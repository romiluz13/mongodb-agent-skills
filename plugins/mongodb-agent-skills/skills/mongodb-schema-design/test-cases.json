{
  "skill": "mongodb-schema-design",
  "generatedAt": "2026-02-11T10:50:26.763Z",
  "totalTestCases": 60,
  "summary": {
    "badExamples": 29,
    "goodExamples": 31
  },
  "testCases": [
    {
      "ruleId": "antipattern-bloated-documents",
      "ruleTitle": "Avoid Bloated Documents",
      "type": "bad",
      "code": "// Product with full history and all images embedded\n// Problem: 665KB loaded into RAM just to show product name and price\n{\n  _id: \"prod123\",\n  name: \"Laptop\",           // 10 bytes - what you need\n  price: 999,               // 8 bytes - what you need\n  description: \"...\",       // 5KB - rarely needed\n  fullSpecs: {...},         // 10KB - rarely needed\n  images: [...],            // 500KB base64 - almost never needed\n  reviews: [...],           // 100KB - paginated separately\n  priceHistory: [...]       // 50KB - analytics only\n}\n// Total: ~665KB per product\n// 1GB RAM = 1,500 products cached (should be 150,000)",
      "language": "javascript",
      "description": "everything in one document"
    },
    {
      "ruleId": "antipattern-bloated-documents",
      "ruleTitle": "Avoid Bloated Documents",
      "type": "good",
      "code": "// Product - hot data only (~500 bytes)\n// This is what 95% of queries actually need\n{\n  _id: \"prod123\",\n  name: \"Laptop\",\n  price: 999,\n  thumbnail: \"https://cdn.example.com/prod123-thumb.jpg\",\n  avgRating: 4.5,\n  reviewCount: 127,\n  inStock: true\n}\n// 1GB RAM = 2,000,000 products cached\n\n// Cold data in separate collections - loaded only when needed\n// products_details: { productId, description, fullSpecs }\n// products_images: { productId, images: [...] }\n// products_reviews: { productId, reviews: [...] }  // paginated\n\n// Product detail page: 2 queries instead of 1, but 100× faster\nconst product = await db.products.findOne({ _id })           // 0.5KB from cache\nconst details = await db.products_details.findOne({ productId })  // 15KB",
      "language": "javascript",
      "description": "hot data only in main document"
    },
    {
      "ruleId": "antipattern-excessive-lookups",
      "ruleTitle": "Reduce Excessive $lookup Usage",
      "type": "bad",
      "code": "// Every product page requires 3 collection scans\ndb.products.aggregate([\n  { $match: { _id: productId } },\n  { $lookup: {\n      from: \"categories\",          // Collection scan #2\n      localField: \"categoryId\",\n      foreignField: \"_id\",\n      as: \"category\"\n  }},\n  { $lookup: {\n      from: \"brands\",              // Collection scan #3\n      localField: \"brandId\",\n      foreignField: \"_id\",\n      as: \"brand\"\n  }},\n  { $unwind: \"$category\" },\n  { $unwind: \"$brand\" }\n])\n// 3 queries, 3× network round-trips, 3× query planning overhead\n// With 100K products: 100K × 3 = 300K operations for listing page",
      "language": "javascript",
      "description": "constant $lookup for common operations"
    },
    {
      "ruleId": "antipattern-excessive-lookups",
      "ruleTitle": "Reduce Excessive $lookup Usage",
      "type": "good",
      "code": "// Embed data that's always displayed with product\n{\n  _id: \"prod123\",\n  name: \"Laptop Pro\",\n  price: 1299,\n  // Denormalized from categories collection\n  category: {\n    _id: \"cat-electronics\",\n    name: \"Electronics\",\n    path: \"Electronics > Computers > Laptops\"\n  },\n  // Denormalized from brands collection\n  brand: {\n    _id: \"brand-acme\",\n    name: \"Acme Corp\",\n    logo: \"https://cdn.example.com/acme.png\"\n  }\n}\n\n// Single indexed query, no $lookup needed\ndb.products.findOne({ _id: \"prod123\" })\n// Or listing: 50 products in single query, <5ms total\ndb.products.find({ \"category._id\": \"cat-electronics\" }).limit(50)",
      "language": "javascript",
      "description": "denormalize frequently-joined data"
    },
    {
      "ruleId": "antipattern-massive-arrays",
      "ruleTitle": "Limit Array Size",
      "type": "bad",
      "code": "// Blog post with all comments embedded\n// Problem: Each $push rewrites the entire 2.5MB array\n{\n  _id: \"post123\",\n  title: \"Popular Post\",\n  comments: [\n    // 5,000 comments, each ~500 bytes = 2.5MB\n    { author: \"user1\", text: \"Great post!\", ts: ISODate(\"...\") },\n    // ... 4,999 more\n  ]\n}\n\n// Adding one comment rewrites 2.5MB on disk\n// If you have an index on comments.author, that's 5,000 index entries\ndb.posts.updateOne(\n  { _id: \"post123\" },\n  { $push: { comments: newComment } }\n)\n// Write time: 200-500ms, locks document during write",
      "language": "javascript",
      "description": "large embedded arrays"
    },
    {
      "ruleId": "antipattern-massive-arrays",
      "ruleTitle": "Limit Array Size",
      "type": "good",
      "code": "// Post with only recent comments (hard limit: 20)\n{\n  _id: \"post123\",\n  title: \"Popular Post\",\n  recentComments: [/* last 20 comments only, ~10KB */],\n  commentCount: 5000\n}\n\n// All comments in separate collection\n// Each comment is an independent document\n{\n  _id: ObjectId(\"...\"),\n  postId: \"post123\",\n  author: \"user1\",\n  text: \"Great post!\",\n  ts: ISODate(\"2024-01-15\")\n}\n\n// Add comment: atomic update with $slice keeps array bounded\ndb.posts.updateOne(\n  { _id: \"post123\" },\n  {\n    $push: {\n      recentComments: {\n        $each: [newComment],\n        $slice: -20,        // Keep only last 20\n        $sort: { ts: -1 }   // Most recent first\n      }\n    },\n    $inc: { commentCount: 1 }\n  }\n)\n// Simultaneously insert into comments collection\ndb.comments.insertOne({ postId: \"post123\", ...newComment })\n// Write time: <5ms",
      "language": "javascript",
      "description": "bounded array + overflow collection"
    },
    {
      "ruleId": "antipattern-schema-drift",
      "ruleTitle": "Prevent Schema Drift",
      "type": "bad",
      "code": "// Over time, different versions of \"user\" documents accumulate\n// Version 1 (2020)\n{ _id: 1, name: \"Alice\", email: \"alice@ex.com\" }\n\n// Version 2 (2021) - added phone\n{ _id: 2, name: \"Bob\", email: \"bob@ex.com\", phone: \"555-1234\" }\n\n// Version 3 (2022) - restructured name\n{ _id: 3, firstName: \"Carol\", lastName: \"Smith\", email: \"carol@ex.com\" }\n\n// Version 4 (2023) - email is now array\n{ _id: 4, firstName: \"Dave\", lastName: \"Jones\", emails: [\"dave@ex.com\", \"d@work.com\"] }\n\n// Application code becomes defensive nightmare\nfunction getUserEmail(user) {\n  if (user.email) return user.email\n  if (user.emails) return user.emails[0]\n  throw new Error(\"No email found\")  // Crashes on some documents\n}\n\n// Queries fail silently\ndb.users.find({ email: \"test@ex.com\" })  // Misses users with emails[] array",
      "language": "javascript",
      "description": "uncontrolled schema drift"
    },
    {
      "ruleId": "antipattern-schema-drift",
      "ruleTitle": "Prevent Schema Drift",
      "type": "good",
      "code": "// Define and enforce consistent schema\ndb.createCollection(\"users\", {\n  validator: {\n    $jsonSchema: {\n      bsonType: \"object\",\n      required: [\"email\", \"profile\"],\n      properties: {\n        email: {\n          bsonType: \"string\",\n          pattern: \"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}$\"\n        },\n        profile: {\n          bsonType: \"object\",\n          required: [\"firstName\", \"lastName\"],\n          properties: {\n            firstName: { bsonType: \"string\", minLength: 1 },\n            lastName: { bsonType: \"string\", minLength: 1 }\n          }\n        },\n        phones: {\n          bsonType: \"array\",\n          items: { bsonType: \"string\" }\n        },\n        schemaVersion: {\n          bsonType: \"int\",\n          enum: [1]  // Current version\n        }\n      }\n    }\n  },\n  validationLevel: \"strict\",\n  validationAction: \"error\"\n})\n\n// All documents now have consistent structure\n{\n  _id: 1,\n  email: \"alice@example.com\",\n  profile: { firstName: \"Alice\", lastName: \"Smith\" },\n  phones: [\"555-1234\"],\n  schemaVersion: 1\n}",
      "language": "javascript",
      "description": "controlled schema with validation"
    },
    {
      "ruleId": "antipattern-unbounded-arrays",
      "ruleTitle": "Avoid Unbounded Arrays",
      "type": "bad",
      "code": "// User document with unbounded activity log\n// Problem: After 1 year, this array has 100,000+ entries\n// Impact: Document size ~15MB, updates take 500ms+, approaching crash\n{\n  _id: \"user123\",\n  name: \"Alice\",\n  activityLog: [\n    { action: \"login\", ts: ISODate(\"2024-01-01\") },\n    { action: \"purchase\", ts: ISODate(\"2024-01-02\") },\n    // ... grows to 100,000+ entries over time\n    // Each entry ~150 bytes × 100,000 = 15MB\n  ]\n}",
      "language": "javascript",
      "description": "array grows forever"
    },
    {
      "ruleId": "antipattern-unbounded-arrays",
      "ruleTitle": "Avoid Unbounded Arrays",
      "type": "good",
      "code": "// User document (bounded, ~200 bytes)\n{ _id: \"user123\", name: \"Alice\", lastActivity: ISODate(\"2024-01-02\") }\n\n// Activity in separate collection (one document per event)\n// Each document ~150 bytes, independent writes, no size limits\n{ userId: \"user123\", action: \"login\", ts: ISODate(\"2024-01-01\") }\n{ userId: \"user123\", action: \"purchase\", ts: ISODate(\"2024-01-02\") }\n\n// Query recent activity with index on {userId, ts}\ndb.activities.find({ userId: \"user123\" }).sort({ ts: -1 }).limit(10)",
      "language": "javascript",
      "description": "separate collection with reference"
    },
    {
      "ruleId": "antipattern-unnecessary-collections",
      "ruleTitle": "Reduce Unnecessary Collections",
      "type": "bad",
      "code": "// 5 collections for one order - relational thinking in MongoDB\n// orders: { _id, customerId, date, status }\n// order_items: { orderId, productId, quantity, price }\n// products: { _id, name, sku }\n// customers: { _id, name, email }\n// addresses: { customerId, street, city }\n\n// Displaying one order requires 5 queries or complex $lookup chain\ndb.orders.aggregate([\n  { $match: { _id: orderId } },\n  { $lookup: { from: \"order_items\", localField: \"_id\", foreignField: \"orderId\", as: \"items\" } },\n  { $unwind: \"$items\" },\n  { $lookup: { from: \"products\", localField: \"items.productId\", foreignField: \"_id\", as: \"items.product\" } },\n  { $lookup: { from: \"customers\", localField: \"customerId\", foreignField: \"_id\", as: \"customer\" } },\n  { $lookup: { from: \"addresses\", localField: \"customerId\", foreignField: \"customerId\", as: \"address\" } }\n])\n// 5 collection scans, O(n×m×p×q×r) complexity\n// Response time: 50-500ms depending on data size",
      "language": "javascript",
      "description": "SQL-style normalization"
    },
    {
      "ruleId": "antipattern-unnecessary-collections",
      "ruleTitle": "Reduce Unnecessary Collections",
      "type": "good",
      "code": "// Single document contains everything needed for order operations\n{\n  _id: \"order123\",\n  date: ISODate(\"2024-01-15\"),\n  status: \"shipped\",\n  // Customer snapshot at time of order (won't change)\n  customer: {\n    _id: \"cust456\",\n    name: \"Alice Smith\",\n    email: \"alice@example.com\"\n  },\n  // Address at time of order (historical accuracy)\n  shippingAddress: {\n    street: \"123 Main St\",\n    city: \"Boston\",\n    state: \"MA\",\n    zip: \"02101\"\n  },\n  // Line items with product snapshot (price at time of order)\n  items: [\n    {\n      sku: \"LAPTOP-01\",\n      name: \"Laptop Pro\",  // Snapshot, won't change if product renamed\n      quantity: 1,\n      unitPrice: 999,\n      lineTotal: 999\n    },\n    {\n      sku: \"MOUSE-02\",\n      name: \"Wireless Mouse\",\n      quantity: 2,\n      unitPrice: 29,\n      lineTotal: 58\n    }\n  ],\n  subtotal: 1057,\n  tax: 84.56,\n  total: 1141.56\n}\n\n// One query returns complete order - no joins needed\ndb.orders.findOne({ _id: \"order123\" })\n// Response time: <5ms",
      "language": "javascript",
      "description": "embedded document model"
    },
    {
      "ruleId": "fundamental-16mb-awareness",
      "ruleTitle": "Respect the 16MB Document Limit",
      "type": "good",
      "code": "// Instead of unbounded arrays, use separate collection\n// User document stays small\n{\n  _id: \"user1\",\n  name: \"Alice\",\n  activityCount: 100000,\n  lastActivity: ISODate(\"2024-01-15\")\n}\n\n// Activities in separate collection\n{\n  userId: \"user1\",\n  action: \"login\",\n  ts: ISODate(\"2024-01-15\"),\n  ip: \"192.168.1.1\"\n}\n\n// Instead of embedded binary, use GridFS\nconst bucket = new GridFSBucket(db)\nconst uploadStream = bucket.openUploadStream(\"report.pdf\")\n// Store file reference in document\n{\n  _id: \"doc1\",\n  content: \"...\",\n  attachments: [\n    { filename: \"report.pdf\", gridfsId: ObjectId(\"...\") }\n  ]\n}",
      "language": "javascript",
      "description": "design for size constraints"
    },
    {
      "ruleId": "fundamental-data-together",
      "ruleTitle": "Store Data That's Accessed Together",
      "type": "bad",
      "code": "// Designed like SQL tables - 3 queries for one page\n// articles: { _id, title, content, authorId }\n// authors: { _id, name, bio }\n// article_tags: { articleId, tag }\n\n// Display article page requires 3 separate queries\nconst article = await db.articles.findOne({ _id: articleId })  // Query 1\nconst author = await db.authors.findOne({ _id: article.authorId })  // Query 2\nconst tags = await db.article_tags.find({ articleId }).toArray()  // Query 3\n// 3 round-trips, 3 index lookups, application joins\n// If author query fails, you still show partial page? Complexity grows.",
      "language": "javascript",
      "description": "entity-based design"
    },
    {
      "ruleId": "fundamental-data-together",
      "ruleTitle": "Store Data That's Accessed Together",
      "type": "good",
      "code": "// Everything needed for article page in one document\n// Schema matches the API response shape\n{\n  _id: \"article123\",\n  title: \"MongoDB Best Practices\",\n  content: \"...\",\n  author: {\n    _id: \"auth456\",           // Keep reference for author profile link\n    name: \"Jane Developer\",    // Embedded for display\n    avatar: \"https://...\"      // Embedded for display\n  },\n  tags: [\"mongodb\", \"database\", \"performance\"],  // Embedded array\n  publishedAt: ISODate(\"2024-01-15\"),\n  readingTime: 8\n}\n\n// Single query returns complete article - 1ms response\nconst article = await db.articles.findOne({ _id: articleId })\n// API response can return document directly - no transformation",
      "language": "javascript",
      "description": "query-based design"
    },
    {
      "ruleId": "fundamental-document-model",
      "ruleTitle": "Embrace the Document Model",
      "type": "bad",
      "code": "// SQL-style: 4 collections for one entity\n// customers: { _id, name, email }\n// addresses: { _id, customerId, type, street, city, zip }\n// phones: { _id, customerId, type, number }\n// preferences: { _id, customerId, key, value }\n\n// To load customer profile: 4 queries required\nconst customer = db.customers.findOne({ _id: \"cust123\" })  // Query 1\nconst addresses = db.addresses.find({ customerId: \"cust123\" })  // Query 2\nconst phones = db.phones.find({ customerId: \"cust123\" })  // Query 3\nconst prefs = db.preferences.find({ customerId: \"cust123\" })  // Query 4\n// Total: 4 round-trips, 4 index lookups, application-side joining\n// Update requires transaction or risks inconsistency",
      "language": "javascript",
      "description": "SQL patterns in MongoDB"
    },
    {
      "ruleId": "fundamental-document-model",
      "ruleTitle": "Embrace the Document Model",
      "type": "good",
      "code": "// Customer document contains everything about the customer\n// All data retrieved in single read, updated atomically\n{\n  _id: \"cust123\",\n  name: \"Alice Smith\",\n  email: \"alice@example.com\",\n  addresses: [\n    { type: \"home\", street: \"123 Main\", city: \"Boston\", zip: \"02101\" },\n    { type: \"work\", street: \"456 Oak\", city: \"Boston\", zip: \"02102\" }\n  ],\n  phones: [\n    { type: \"mobile\", number: \"555-1234\" },\n    { type: \"work\", number: \"555-5678\" }\n  ],\n  preferences: {\n    newsletter: true,\n    theme: \"dark\",\n    language: \"en\"\n  },\n  createdAt: ISODate(\"2024-01-01\")\n}\n\n// Single query loads complete customer - 1 round-trip\ndb.customers.findOne({ _id: \"cust123\" })\n\n// Atomic update - no transaction needed\ndb.customers.updateOne(\n  { _id: \"cust123\" },\n  { $push: { addresses: newAddress }, $set: { \"preferences.theme\": \"light\" } }\n)",
      "language": "javascript",
      "description": "rich document model"
    },
    {
      "ruleId": "fundamental-embed-vs-reference",
      "ruleTitle": "Embed vs Reference Decision Framework",
      "type": "bad",
      "code": "// User with embedded profile - single document\n// Always consistent, always atomic\n{\n  _id: \"user123\",\n  email: \"alice@example.com\",\n  profile: {\n    name: \"Alice Smith\",\n    avatar: \"https://cdn.example.com/alice.jpg\",\n    bio: \"Software developer\"\n  },\n  createdAt: ISODate(\"2024-01-01\")\n}\n\n// Single query returns everything\nconst user = await db.users.findOne({ _id: userId })\n// Atomic updates - profile can't exist without user\ndb.users.updateOne(\n  { _id: userId },\n  { $set: { \"profile.name\": \"Alice Johnson\" } }\n)",
      "language": "javascript",
      "description": "reference when should embed"
    },
    {
      "ruleId": "fundamental-embed-vs-reference",
      "ruleTitle": "Embed vs Reference Decision Framework",
      "type": "bad",
      "code": "// Blog post with ALL comments embedded - unbounded!\n{\n  _id: \"post123\",\n  title: \"Popular Post\",\n  comments: [\n    // 50,000 comments × 500 bytes = 25MB document\n    // Exceeds 16MB BSON limit - APPLICATION CRASH\n    { author: \"user1\", text: \"...\", ts: ISODate(\"...\") },\n    // ... grows forever\n  ]\n}",
      "language": "javascript",
      "description": "embed when should reference"
    },
    {
      "ruleId": "fundamental-embed-vs-reference",
      "ruleTitle": "Embed vs Reference Decision Framework",
      "type": "good",
      "code": "// Post with comment summary embedded\n{\n  _id: \"post123\",\n  title: \"Popular Post\",\n  commentCount: 50000,\n  recentComments: [/* last 5 only - bounded */]\n}\n\n// Comments in separate collection - no limit\n{\n  _id: ObjectId(\"...\"),\n  postId: \"post123\",\n  author: \"user1\",\n  text: \"Great post!\",\n  ts: ISODate(\"2024-01-15\")\n}\n// Index on postId for efficient lookups",
      "language": "javascript",
      "description": "reference unbounded data"
    },
    {
      "ruleId": "fundamental-schema-validation",
      "ruleTitle": "Use Schema Validation",
      "type": "bad",
      "code": "// Any document can be inserted - no safety net\ndb.users.insertOne({ email: \"not-an-email\", age: \"twenty\" })\n// Now you have: { email: \"not-an-email\", age: \"twenty\" }\n// Application crashes when parsing age as number\n// Or worse: silent data corruption, discovered months later\n\ndb.users.insertOne({ name: \"Bob\" })  // Missing required email\n// Downstream systems expect email, fail silently",
      "language": "javascript",
      "description": "no validation"
    },
    {
      "ruleId": "fundamental-schema-validation",
      "ruleTitle": "Use Schema Validation",
      "type": "good",
      "code": "// Create collection with validation rules\ndb.createCollection(\"users\", {\n  validator: {\n    $jsonSchema: {\n      bsonType: \"object\",\n      required: [\"email\", \"name\"],\n      properties: {\n        email: {\n          bsonType: \"string\",\n          pattern: \"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}$\",\n          description: \"must be a valid email address\"\n        },\n        name: {\n          bsonType: \"string\",\n          minLength: 1,\n          maxLength: 100,\n          description: \"must be 1-100 characters\"\n        },\n        age: {\n          bsonType: \"int\",\n          minimum: 0,\n          maximum: 150,\n          description: \"must be integer 0-150\"\n        },\n        status: {\n          enum: [\"active\", \"inactive\", \"pending\"],\n          description: \"must be one of: active, inactive, pending\"\n        },\n        addresses: {\n          bsonType: \"array\",\n          maxItems: 10,  // Prevent unbounded arrays\n          items: {\n            bsonType: \"object\",\n            required: [\"city\"],\n            properties: {\n              street: { bsonType: \"string\" },\n              city: { bsonType: \"string\" },\n              zip: { bsonType: \"string\", pattern: \"^[0-9]{5}$\" }\n            }\n          }\n        }\n      }\n    }\n  },\n  validationLevel: \"strict\",\n  validationAction: \"error\"\n})\n\n// Invalid inserts now fail immediately with clear error\ndb.users.insertOne({ email: \"not-an-email\" })\n// Error: Document failed validation:\n// \"email\" does not match pattern, \"name\" is required",
      "language": "javascript",
      "description": "schema validation"
    },
    {
      "ruleId": "pattern-archive",
      "ruleTitle": "Use Archive Pattern for Historical Data",
      "type": "bad",
      "code": "// Sales collection with 5 years of data\n// 50 million documents, only recent 6 months actively queried\ndb.sales.find({ date: { $gte: lastMonth } })\n\n// Problems:\n// 1. Index on date covers 50M docs, only 1M relevant\n// 2. Working set includes old data pages\n// 3. Backups include rarely-accessed historical data\n// 4. Storage costs for hot tier when cold would suffice",
      "language": "javascript",
      "description": "all data in one collection"
    },
    {
      "ruleId": "pattern-archive",
      "ruleTitle": "Use Archive Pattern for Historical Data",
      "type": "good",
      "code": "// Step 1: Define archive threshold\nconst fiveYearsAgo = new Date()\nfiveYearsAgo.setFullYear(fiveYearsAgo.getFullYear() - 5)\n\n// Step 2: Move old data to archive collection using $merge\ndb.sales.aggregate([\n  { $match: { date: { $lt: fiveYearsAgo } } },\n  { $merge: {\n      into: \"sales_archive\",\n      on: \"_id\",\n      whenMatched: \"keepExisting\",  // Don't overwrite if re-run\n      whenNotMatched: \"insert\"\n    }\n  }\n])\n\n// Step 3: Delete archived data from active collection\ndb.sales.deleteMany({ date: { $lt: fiveYearsAgo } })\n\n// Result:\n// - sales: Recent data, fast queries, small indexes\n// - sales_archive: Historical data, rarely queried",
      "language": "javascript",
      "description": "archive old data separately"
    },
    {
      "ruleId": "pattern-attribute",
      "ruleTitle": "Use Attribute Pattern for Sparse or Variable Fields",
      "type": "bad",
      "code": "// Many optional fields - most are null or missing\n{\n  _id: 1,\n  name: \"Bottle\",\n  color: \"red\",\n  size: \"M\",\n  material: \"glass\",\n  // 20+ other optional fields\n}\n\n// Index explosion\n// db.items.createIndex({ color: 1 })\n// db.items.createIndex({ size: 1 })\n// db.items.createIndex({ material: 1 })",
      "language": "javascript",
      "description": "many optional fields and indexes"
    },
    {
      "ruleId": "pattern-attribute",
      "ruleTitle": "Use Attribute Pattern for Sparse or Variable Fields",
      "type": "good",
      "code": "// Store optional fields as key-value pairs\n{\n  _id: 1,\n  name: \"Bottle\",\n  attributes: [\n    { k: \"color\", v: \"red\" },\n    { k: \"size\", v: \"M\" },\n    { k: \"material\", v: \"glass\" }\n  ]\n}\n\n// Single multikey index for all attributes\n\ndb.items.createIndex({ \"attributes.k\": 1, \"attributes.v\": 1 })\n\n// Query for color = red\n\ndb.items.find({\n  attributes: { $elemMatch: { k: \"color\", v: \"red\" } }\n})",
      "language": "javascript",
      "description": "attribute pattern"
    },
    {
      "ruleId": "pattern-bucket",
      "ruleTitle": "Use Bucket Pattern for Time-Series Data",
      "type": "bad",
      "code": "// Sensor readings: 1 document per reading\n// Each document ~100 bytes + index entries\n{ sensorId: \"temp-01\", ts: ISODate(\"2024-01-15T10:00:00Z\"), value: 22.5 }\n{ sensorId: \"temp-01\", ts: ISODate(\"2024-01-15T10:00:01Z\"), value: 22.6 }\n{ sensorId: \"temp-01\", ts: ISODate(\"2024-01-15T10:00:02Z\"), value: 22.5 }\n// ...\n\n// Per sensor per year:\n// 86,400 docs/day × 365 days = 31,536,000 documents\n// 31M index entries for {sensorId, ts} compound index\n// Query for 1 day: scan 86,400 index entries",
      "language": "javascript",
      "description": "one document per event"
    },
    {
      "ruleId": "pattern-bucket",
      "ruleTitle": "Use Bucket Pattern for Time-Series Data",
      "type": "good",
      "code": "// One document per sensor per hour\n// Readings array bounded to ~3,600 elements\n{\n  sensorId: \"temp-01\",\n  bucket: ISODate(\"2024-01-15T10:00:00Z\"),  // Hour start\n  readings: [\n    { m: 0, s: 0, value: 22.5 },   // Minute 0, second 0\n    { m: 0, s: 1, value: 22.6 },   // Minute 0, second 1\n    { m: 0, s: 2, value: 22.5 },\n    // ... up to 3,600 readings\n  ],\n  count: 3600,\n  // Pre-computed aggregates - no need to scan array\n  sum: 81234.5,\n  min: 21.2,\n  max: 24.8,\n  avg: 22.56\n}\n\n// Per sensor per year:\n// 24 docs/day × 365 days = 8,760 documents (3,600× fewer)\n// 8,760 index entries (3,600× smaller index)\n// Query for 1 day: scan 24 index entries",
      "language": "javascript",
      "description": "bucket pattern - group by time window"
    },
    {
      "ruleId": "pattern-computed",
      "ruleTitle": "Use Computed Pattern for Expensive Calculations",
      "type": "bad",
      "code": "// Movie with all screenings in separate collection\n{ _id: \"movie1\", title: \"The Matrix\" }\n\n// Screenings collection - thousands of records\n{ movieId: \"movie1\", date: ISODate(\"...\"), viewers: 344, revenue: 3440 }\n{ movieId: \"movie1\", date: ISODate(\"...\"), viewers: 256, revenue: 2560 }\n// ... 10,000 screenings\n\n// Movie page aggregates every time\ndb.screenings.aggregate([\n  { $match: { movieId: \"movie1\" } },\n  { $group: {\n    _id: \"$movieId\",\n    totalViewers: { $sum: \"$viewers\" },\n    totalRevenue: { $sum: \"$revenue\" },\n    screeningCount: { $sum: 1 }\n  }}\n])\n// 50-500ms per page load, scanning 10,000 documents\n// 1M page views/day = 1M expensive aggregations",
      "language": "javascript",
      "description": "calculate on every read"
    },
    {
      "ruleId": "pattern-computed",
      "ruleTitle": "Use Computed Pattern for Expensive Calculations",
      "type": "good",
      "code": "// Movie with computed stats stored directly\n{\n  _id: \"movie1\",\n  title: \"The Matrix\",\n  stats: {\n    totalViewers: 1840000,\n    totalRevenue: 25880000,\n    screeningCount: 8500,\n    avgViewersPerScreening: 216,\n    computedAt: ISODate(\"2024-01-15T00:00:00Z\")\n  }\n}\n\n// Movie page: instant read, no aggregation\ndb.movies.findOne({ _id: \"movie1\" })\n// <5ms, single document read",
      "language": "javascript",
      "description": "pre-computed values"
    },
    {
      "ruleId": "pattern-extended-reference",
      "ruleTitle": "Use Extended Reference Pattern",
      "type": "bad",
      "code": "// Order references customer by ID only\n{\n  _id: \"order123\",\n  customerId: \"cust456\",  // Just an ObjectId\n  items: [...],\n  total: 299.99\n}\n\n// Every order list/display requires $lookup\ndb.orders.aggregate([\n  { $match: { status: \"pending\" } },\n  { $lookup: {\n    from: \"customers\",\n    localField: \"customerId\",\n    foreignField: \"_id\",\n    as: \"customer\"\n  }},\n  { $unwind: \"$customer\" }\n])\n// 50 orders × $lookup = 50 extra index lookups\n// List view: 50-200ms instead of 5-20ms",
      "language": "javascript",
      "description": "always $lookup for display data"
    },
    {
      "ruleId": "pattern-extended-reference",
      "ruleTitle": "Use Extended Reference Pattern",
      "type": "good",
      "code": "// Order contains frequently-needed customer fields\n// Full customer data still in customers collection\n{\n  _id: \"order123\",\n  customer: {\n    _id: \"cust456\",         // Keep reference for full lookup\n    name: \"Alice Smith\",    // Cached for display\n    email: \"alice@ex.com\"   // Cached for notifications\n  },\n  items: [...],\n  total: 299.99,\n  createdAt: ISODate(\"2024-01-15\")\n}\n\n// Order list without $lookup - single query\ndb.orders.find({ status: \"pending\" })\n// Returns customer.name directly - no join needed\n// 50 orders in 5ms instead of 50ms\n\n// Full customer data available when needed\nconst fullCustomer = db.customers.findOne({ _id: order.customer._id })",
      "language": "javascript",
      "description": "extended reference"
    },
    {
      "ruleId": "pattern-outlier",
      "ruleTitle": "Use Outlier Pattern for Exceptional Documents",
      "type": "good",
      "code": "// Typical book - unchanged\n{\n  _id: \"book1\",\n  title: \"Normal Book\",\n  customers: [\"cust1\", \"cust2\", /* ... 50 items */],\n  hasExtras: false  // Flag for application logic\n}\n\n// Bestseller - capped at threshold\n{\n  _id: \"book2\",\n  title: \"Harry Potter\",\n  customers: [/* first 50 items only */],\n  hasExtras: true,  // Flag indicating overflow exists\n  customerCount: 50000  // Denormalized count\n}\n\n// Overflow in separate collection\n{\n  _id: ObjectId(\"...\"),\n  bookId: \"book2\",\n  customers: [/* items 51-1000 */],\n  batch: 1\n}\n{\n  _id: ObjectId(\"...\"),\n  bookId: \"book2\",\n  customers: [/* items 1001-2000 */],\n  batch: 2\n}\n// ...additional batches as needed",
      "language": "javascript",
      "description": "outlier pattern"
    },
    {
      "ruleId": "pattern-polymorphic",
      "ruleTitle": "Use Polymorphic Pattern for Heterogeneous Documents",
      "type": "bad",
      "code": "// Separate collections for each product type\ndb.products_books.find({})\ndb.products_electronics.find({})\ndb.products_clothing.find({})\n\n// Problems:\n// 1. Queries across all products need multiple calls or $unionWith\n// 2. Shared indexes must be duplicated\n// 3. Adding new types requires new collections\n// 4. Application code branches on collection names\n\n// Querying all products is painful:\nconst allProducts = [\n  ...db.products_books.find({ price: { $lt: 50 } }).toArray(),\n  ...db.products_electronics.find({ price: { $lt: 50 } }).toArray(),\n  ...db.products_clothing.find({ price: { $lt: 50 } }).toArray()\n]",
      "language": "javascript",
      "description": "separate collections per subtype"
    },
    {
      "ruleId": "pattern-polymorphic",
      "ruleTitle": "Use Polymorphic Pattern for Heterogeneous Documents",
      "type": "good",
      "code": "// Single collection with type field as discriminator\n// All products share common fields, type-specific fields vary\n\n// Book\n{\n  _id: ObjectId(\"...\"),\n  type: \"book\",\n  name: \"MongoDB: The Definitive Guide\",\n  price: 49.99,\n  inStock: true,\n  // Book-specific fields\n  author: \"Shannon Bradshaw\",\n  isbn: \"978-1491954461\",\n  pages: 514\n}\n\n// Electronics\n{\n  _id: ObjectId(\"...\"),\n  type: \"electronics\",\n  name: \"Wireless Headphones\",\n  price: 79.99,\n  inStock: true,\n  // Electronics-specific fields\n  brand: \"Sony\",\n  wattage: 20,\n  batteryHours: 30,\n  warranty: \"2 years\"\n}\n\n// Clothing\n{\n  _id: ObjectId(\"...\"),\n  type: \"clothing\",\n  name: \"Running Shoes\",\n  price: 129.99,\n  inStock: false,\n  // Clothing-specific fields\n  size: [\"S\", \"M\", \"L\", \"XL\"],\n  color: \"blue\",\n  material: \"synthetic\"\n}\n\n// Query all products easily:\ndb.products.find({ price: { $lt: 100 } })\n\n// Query specific type:\ndb.products.find({ type: \"book\", author: \"Shannon Bradshaw\" })",
      "language": "javascript",
      "description": "single collection with discriminator"
    },
    {
      "ruleId": "pattern-schema-versioning",
      "ruleTitle": "Use Schema Versioning for Safe Evolution",
      "type": "bad",
      "code": "// Version 1: address is a string\n{ _id: 1, name: \"Ada\", address: \"12 Main St, NYC 10001\" }\n\n// Developer changes schema: address becomes an object\n// New code expects:\n{ _id: 1, name: \"Ada\", address: { street: \"12 Main St\", city: \"NYC\", zip: \"10001\" } }\n\n// PROBLEMS:\n// 1. Old documents break: address.city returns undefined\n// 2. Application crashes or returns wrong data\n// 3. Can't deploy gradually - all-or-nothing\n// 4. Rollback is dangerous if new docs were written",
      "language": "javascript",
      "description": "breaking change without versioning"
    },
    {
      "ruleId": "pattern-schema-versioning",
      "ruleTitle": "Use Schema Versioning for Safe Evolution",
      "type": "good",
      "code": "// Version 1 documents (existing)\n{ _id: 1, name: \"Ada\", schemaVersion: 1, address: \"12 Main St, NYC 10001\" }\n\n// Version 2 documents (new structure)\n{ _id: 2, name: \"Bob\", schemaVersion: 2,\n  address: { street: \"45 Oak Ave\", city: \"Boston\", zip: \"02101\" } }\n\n// Application code handles both versions:\nfunction getCity(user) {\n  if (user.schemaVersion >= 2) {\n    return user.address.city\n  }\n  // Parse city from v1 string format\n  return parseAddressString(user.address).city\n}\n\n// Benefits:\n// 1. Old and new documents coexist\n// 2. Deploy new code before migrating data\n// 3. Gradual migration during low-traffic periods\n// 4. Easy rollback - old code still works",
      "language": "javascript",
      "description": "versioned documents with migration path"
    },
    {
      "ruleId": "pattern-subset",
      "ruleTitle": "Use Subset Pattern for Hot/Cold Data",
      "type": "bad",
      "code": "// Movie with ALL reviews embedded\n// Hot data: title, rating, plot (~1KB)\n// Cold data: 10,000 reviews (~1MB)\n{\n  _id: \"movie123\",\n  title: \"The Matrix\",\n  year: 1999,\n  rating: 8.7,\n  plot: \"A computer hacker learns about the true nature...\",\n  reviews: [\n    // 10,000 reviews × 100 bytes each = 1MB cold data\n    { user: \"critic1\", rating: 5, text: \"Masterpiece...\", date: \"...\" },\n    { user: \"user42\", rating: 4, text: \"Great effects...\", date: \"...\" },\n    // ... 9,998 more reviews, 95% never read\n  ]\n}\n\n// Every movie page load pulls 1MB into RAM\n// 1GB RAM = 1,000 movies cached\n// Most page views only need title + rating + plot",
      "language": "javascript",
      "description": "all data in one document"
    },
    {
      "ruleId": "pattern-subset",
      "ruleTitle": "Use Subset Pattern for Hot/Cold Data",
      "type": "good",
      "code": "// Movie with only hot data (~2KB)\n{\n  _id: \"movie123\",\n  title: \"The Matrix\",\n  year: 1999,\n  rating: 8.7,\n  plot: \"A computer hacker learns about the true nature...\",\n  // Summary stats - no full reviews\n  reviewStats: {\n    count: 10000,\n    avgRating: 4.2,\n    distribution: { 5: 4000, 4: 3000, 3: 2000, 2: 700, 1: 300 }\n  },\n  // Only top 5 featured reviews (~500 bytes)\n  featuredReviews: [\n    { user: \"critic1\", rating: 5, text: \"Masterpiece\", featured: true },\n    { user: \"critic2\", rating: 5, text: \"Revolutionary\", featured: true }\n  ]\n}\n// 1GB RAM = 500,000 movies cached (500× more)\n\n// Cold data: Full reviews in separate collection\n{\n  _id: ObjectId(\"...\"),\n  movieId: \"movie123\",\n  user: \"user456\",\n  rating: 4,\n  text: \"Great visual effects and deep storyline...\",\n  date: ISODate(\"2024-01-15\"),\n  helpful: 42\n}\n// Only loaded when user clicks \"Show all reviews\"",
      "language": "javascript",
      "description": "subset pattern"
    },
    {
      "ruleId": "pattern-time-series-collections",
      "ruleTitle": "Use Time Series Collections for Time Series Data",
      "type": "bad",
      "code": "// Regular collection: one document per reading\n// Creates huge collections and indexes at scale\n{\n  sensorId: \"temp-01\",\n  ts: ISODate(\"2025-01-15T10:00:00Z\"),\n  value: 22.5\n}\n\n// Problems:\n// 1. Each measurement is a separate document\n// 2. Index overhead per document\n// 3. No automatic compression\n// 4. Working set grows linearly\n\n// Standard index (large and grows fast)\ndb.sensor_data.createIndex({ sensorId: 1, ts: 1 })",
      "language": "javascript",
      "description": "regular collection for measurements"
    },
    {
      "ruleId": "pattern-time-series-collections",
      "ruleTitle": "Use Time Series Collections for Time Series Data",
      "type": "good",
      "code": "// Create time series collection with careful configuration\ndb.createCollection(\"sensor_data\", {\n  timeseries: {\n    timeField: \"ts\",           // Required: timestamp field\n    metaField: \"metadata\",     // Recommended: grouping field\n    granularity: \"minutes\"     // Match your data rate\n  },\n  expireAfterSeconds: 60 * 60 * 24 * 90  // 90-day retention\n})\n\n// Insert documents - MongoDB buckets automatically\ndb.sensor_data.insertOne({\n  metadata: { sensorId: \"temp-01\", location: \"building-A\" },\n  ts: new Date(),\n  value: 22.5,\n  unit: \"celsius\"\n})\n\n// Benefits:\n// - Automatic bucketing (many measurements per internal doc)\n// - Column compression (40-60% disk reduction)\n// - Auto-created compound index on metaField + timeField\n// - Optimized for time-range queries",
      "language": "javascript",
      "description": "time series collection with optimized settings"
    },
    {
      "ruleId": "relationship-many-to-many",
      "ruleTitle": "Model Many-to-Many Relationships",
      "type": "bad",
      "code": "// SQL thinking: 3 collections, always need joins\n// students: { _id, name }\n// classes: { _id, name }\n// enrollments: { studentId, classId }\n\n// Get student with classes: 2 joins required\ndb.enrollments.aggregate([\n  { $match: { studentId: \"student1\" } },\n  { $lookup: { from: \"classes\", localField: \"classId\", foreignField: \"_id\", as: \"class\" } }\n])\n// Slow, complex, every query needs aggregation",
      "language": "javascript",
      "description": "SQL-style junction table"
    },
    {
      "ruleId": "relationship-many-to-many",
      "ruleTitle": "Model Many-to-Many Relationships",
      "type": "good",
      "code": "// If you query \"which classes is this student in\" most often:\n// Embed class references in student\n{\n  _id: \"student1\",\n  name: \"Alice Smith\",\n  classes: [\n    { classId: \"class101\", name: \"Database Systems\", instructor: \"Dr. Smith\" },\n    { classId: \"class102\", name: \"Web Development\", instructor: \"Dr. Jones\" }\n  ]\n}\n\n// If you query \"which students are in this class\" most often:\n// Embed student references in class\n{\n  _id: \"class101\",\n  name: \"Database Systems\",\n  instructor: \"Dr. Smith\",\n  students: [\n    { studentId: \"student1\", name: \"Alice Smith\" },\n    { studentId: \"student2\", name: \"Bob Jones\" }\n  ]\n}",
      "language": "javascript",
      "description": "embed in primary query direction"
    },
    {
      "ruleId": "relationship-one-to-few",
      "ruleTitle": "Model One-to-Few Relationships with Embedded Arrays",
      "type": "bad",
      "code": "// User in users collection\n{ _id: \"user123\", name: \"Alice Smith\" }\n\n// Addresses in separate collection - user typically has 1-3\n{ userId: \"user123\", type: \"home\", street: \"123 Main\", city: \"Boston\" }\n{ userId: \"user123\", type: \"work\", street: \"456 Oak\", city: \"Boston\" }\n\n// User profile page requires $lookup for 2-3 addresses\ndb.users.aggregate([\n  { $match: { _id: \"user123\" } },\n  { $lookup: {\n    from: \"addresses\",\n    localField: \"_id\",\n    foreignField: \"userId\",\n    as: \"addresses\"\n  }}\n])\n// Extra collection scan for ~2 addresses\n// Orphaned addresses when user deleted",
      "language": "javascript",
      "description": "separate collection for few items"
    },
    {
      "ruleId": "relationship-one-to-few",
      "ruleTitle": "Model One-to-Few Relationships with Embedded Arrays",
      "type": "good",
      "code": "// User with embedded addresses - bounded to ~5 max\n{\n  _id: \"user123\",\n  name: \"Alice Smith\",\n  addresses: [\n    { type: \"home\", street: \"123 Main St\", city: \"Boston\", state: \"MA\", zip: \"02101\" },\n    { type: \"work\", street: \"456 Oak Ave\", city: \"Boston\", state: \"MA\", zip: \"02102\" }\n  ]\n}\n\n// Single query returns user with all addresses\ndb.users.findOne({ _id: \"user123\" })\n\n// Add address atomically\ndb.users.updateOne(\n  { _id: \"user123\" },\n  { $push: { addresses: { type: \"vacation\", street: \"789 Beach\", city: \"Miami\" } } }\n)\n\n// Update specific address\ndb.users.updateOne(\n  { _id: \"user123\", \"addresses.type\": \"home\" },\n  { $set: { \"addresses.$.city\": \"Cambridge\" } }\n)",
      "language": "javascript",
      "description": "embedded array"
    },
    {
      "ruleId": "relationship-one-to-many",
      "ruleTitle": "Model One-to-Many Relationships with References",
      "type": "bad",
      "code": "// Publisher with ALL books embedded - will crash at scale\n{\n  _id: \"oreilly\",\n  name: \"O'Reilly Media\",\n  books: [\n    // 10,000+ books × 1KB each = 10MB+ document\n    { title: \"MongoDB: The Definitive Guide\", isbn: \"123\", pages: 400 },\n    { title: \"Learning Python\", isbn: \"456\", pages: 600 },\n    // ... grows forever\n  ]\n}\n// Adding one book rewrites entire 10MB document\n// Eventually exceeds 16MB limit → APPLICATION CRASH",
      "language": "javascript",
      "description": "embedding unbounded arrays"
    },
    {
      "ruleId": "relationship-one-to-many",
      "ruleTitle": "Model One-to-Many Relationships with References",
      "type": "good",
      "code": "// Publisher document (simple, fixed size)\n{\n  _id: \"oreilly\",\n  name: \"O'Reilly Media\",\n  founded: 1980,\n  location: \"CA\",\n  bookCount: 10000  // Denormalized count for display\n}\n\n// Each book references its publisher\n{\n  _id: \"book123\",\n  title: \"MongoDB: The Definitive Guide\",\n  authors: [\"Kristina Chodorow\", \"Mike Dirolf\"],\n  publisher_id: \"oreilly\",  // Reference to publisher\n  isbn: \"978-1449344689\",\n  pages: 432,\n  publishedDate: ISODate(\"2013-05-23\")\n}\n\n// Create index on reference field\ndb.books.createIndex({ publisher_id: 1 })\n\n// Query books by publisher efficiently\ndb.books.find({ publisher_id: \"oreilly\" }).sort({ publishedDate: -1 })\n// Uses index, returns any number of books",
      "language": "javascript",
      "description": "reference in child documents"
    },
    {
      "ruleId": "relationship-one-to-one",
      "ruleTitle": "Model One-to-One Relationships with Embedding",
      "type": "bad",
      "code": "// User account collection\n{ _id: \"user123\", email: \"alice@example.com\", createdAt: ISODate(\"...\") }\n\n// User profile in separate collection - always accessed with user\n{ userId: \"user123\", name: \"Alice Smith\", avatar: \"https://...\", bio: \"Developer\" }\n\n// Every user lookup requires 2 queries\nconst user = db.users.findOne({ _id: \"user123\" })\nconst profile = db.profiles.findOne({ userId: \"user123\" })\n// 2 round-trips, 2 index lookups\n// What if profile insert fails? Orphaned user account\n// What if user deleted? Orphaned profile",
      "language": "javascript",
      "description": "separate collections for one-to-one data"
    },
    {
      "ruleId": "relationship-one-to-one",
      "ruleTitle": "Model One-to-One Relationships with Embedding",
      "type": "good",
      "code": "// Single document contains user + profile\n{\n  _id: \"user123\",\n  email: \"alice@example.com\",\n  createdAt: ISODate(\"2024-01-01\"),\n  profile: {\n    name: \"Alice Smith\",\n    avatar: \"https://cdn.example.com/alice.jpg\",\n    bio: \"Developer building cool things\"\n  }\n}\n\n// Single query returns everything\ndb.users.findOne({ _id: \"user123\" })\n\n// Atomic update - profile can't exist without user\ndb.users.updateOne(\n  { _id: \"user123\" },\n  { $set: { \"profile.name\": \"Alice Johnson\" } }\n)\n\n// Delete user, profile goes with it automatically\ndb.users.deleteOne({ _id: \"user123\" })",
      "language": "javascript",
      "description": "embedded one-to-one document"
    },
    {
      "ruleId": "relationship-one-to-squillions",
      "ruleTitle": "Model One-to-Squillions with References and Summaries",
      "type": "bad",
      "code": "// User document with millions of activity entries\n{\n  _id: \"user123\",\n  name: \"Ada\",\n  activities: [\n    // Unbounded array - will exceed 16MB\n    { ts: ISODate(\"2025-01-01\"), action: \"login\" }\n  ]\n}",
      "language": "javascript",
      "description": "embed massive child arrays"
    },
    {
      "ruleId": "relationship-one-to-squillions",
      "ruleTitle": "Model One-to-Squillions with References and Summaries",
      "type": "good",
      "code": "// Parent with summary only\n{\n  _id: \"user123\",\n  name: \"Ada\",\n  activityCount: 15000000,\n  recentActivities: [\n    { ts: ISODate(\"2025-01-15\"), action: \"login\" }\n  ]\n}\n\n// Child documents in separate collection\n{\n  _id: ObjectId(\"...\"),\n  userId: \"user123\",\n  ts: ISODate(\"2025-01-01\"),\n  action: \"login\"\n}\n\n// Index for efficient fan-out queries\n\ndb.user_activities.createIndex({ userId: 1, ts: -1 })",
      "language": "javascript",
      "description": "reference children + summary in parent"
    },
    {
      "ruleId": "relationship-tree-structures",
      "ruleTitle": "Model Tree and Hierarchical Data",
      "type": "bad",
      "code": "// Using only parent references for breadcrumb navigation\n{ _id: \"MongoDB\", parent: \"Databases\" }\n{ _id: \"Databases\", parent: \"Programming\" }\n{ _id: \"Programming\", parent: null }\n\n// Building breadcrumb requires recursive queries\nasync function getBreadcrumb(categoryId) {\n  const crumbs = []\n  let current = await db.categories.findOne({ _id: categoryId })\n  while (current && current.parent) {\n    current = await db.categories.findOne({ _id: current.parent })\n    crumbs.unshift(current)  // N queries for N-level hierarchy!\n  }\n  return crumbs\n}\n// 5-level deep category = 5 database round-trips per page view",
      "language": "javascript",
      "description": "recursive queries for breadcrumbs"
    },
    {
      "ruleId": "relationship-tree-structures",
      "ruleTitle": "Model Tree and Hierarchical Data",
      "type": "good",
      "code": "// Store full path for O(1) ancestor queries\n{ _id: \"MongoDB\", path: \",Programming,Databases,MongoDB,\", depth: 3 }\n\n// Single query returns all ancestors\nconst category = db.categories.findOne({ _id: \"MongoDB\" })\nconst ancestors = category.path.split(\",\").filter(Boolean)\ndb.categories.find({ _id: { $in: ancestors } }).sort({ depth: 1 })\n// 1 query regardless of depth!",
      "language": "javascript",
      "description": "materialized path for breadcrumbs"
    },
    {
      "ruleId": "relationship-tree-structures",
      "ruleTitle": "Model Tree and Hierarchical Data",
      "type": "good",
      "code": "// Using Materialized Paths for category navigation\n{\n  _id: \"laptop-gaming\",\n  name: \"Gaming Laptops\",\n  path: \",electronics,computers,laptops,laptop-gaming,\",\n  parent: \"laptops\",\n  depth: 4,\n  productCount: 234  // Denormalized for display\n}\n\n// Create indexes\ndb.categories.createIndex({ path: 1 })\ndb.categories.createIndex({ parent: 1 })\n\n// Get full category tree under \"computers\"\ndb.categories.find({ path: /^,electronics,computers,/ }).sort({ path: 1 })\n\n// Get breadcrumb for product page\nconst category = db.categories.findOne({ _id: \"laptop-gaming\" })\nconst breadcrumb = category.path.split(\",\").filter(Boolean)\ndb.categories.find({ _id: { $in: breadcrumb } }).sort({ depth: 1 })",
      "language": "javascript",
      "description": "Recommended patterns by use case example for Model Tree and Hierarchical Data"
    },
    {
      "ruleId": "validation-action-levels",
      "ruleTitle": "Choose Validation Level and Action Appropriately",
      "type": "bad",
      "code": "// Adding strict validation to collection with legacy data\ndb.runCommand({\n  collMod: \"users\",\n  validator: {\n    $jsonSchema: {\n      required: [\"email\", \"name\"],\n      properties: {\n        email: { bsonType: \"string\", pattern: \"^.+@.+$\" }\n      }\n    }\n  },\n  validationLevel: \"strict\",   // Validates ALL documents\n  validationAction: \"error\"    // Rejects invalid\n})\n// Problem: 10,000 existing users without email field\n// Result: All updates to those users fail!\n// \"Document failed validation\" on every updateOne()",
      "language": "javascript",
      "description": "strict validation on existing data"
    },
    {
      "ruleId": "validation-action-levels",
      "ruleTitle": "Choose Validation Level and Action Appropriately",
      "type": "good",
      "code": "// Step 1: Start with warn + moderate to discover issues\ndb.runCommand({\n  collMod: \"users\",\n  validator: { $jsonSchema: { required: [\"email\", \"name\"] } },\n  validationLevel: \"moderate\",  // Skip existing non-matching docs\n  validationAction: \"warn\"      // Log but allow\n})\n\n// Step 2: Find and fix non-compliant documents\ndb.users.find({ email: { $exists: false } })\n// Fix: Add missing emails\n\n// Step 3: Only then switch to strict + error\ndb.runCommand({\n  collMod: \"users\",\n  validationLevel: \"strict\",\n  validationAction: \"error\"\n})",
      "language": "javascript",
      "description": "gradual rollout with moderate level"
    },
    {
      "ruleId": "validation-json-schema",
      "ruleTitle": "Define Validation Rules with JSON Schema",
      "type": "bad",
      "code": "// No schema validation - anything goes\ndb.products.insertOne({ price: \"free\" })      // String instead of number\ndb.products.insertOne({ price: -100 })        // Negative price\ndb.products.insertOne({ name: \"\" })           // Empty name\ndb.products.insertOne({ category: \"xyz123\" }) // Invalid category\n\n// Later in your application:\nconst total = products.reduce((sum, p) => sum + p.price, 0)\n// NaN! Because \"free\" + 100 = NaN\n// Bug discovered months later, data already corrupted",
      "language": "javascript",
      "description": "no validation, data corruption"
    },
    {
      "ruleId": "validation-json-schema",
      "ruleTitle": "Define Validation Rules with JSON Schema",
      "type": "good",
      "code": "db.createCollection(\"products\", {\n  validator: {\n    $jsonSchema: {\n      bsonType: \"object\",\n      required: [\"name\", \"price\", \"category\"],\n      properties: {\n        name: { bsonType: \"string\", minLength: 1 },\n        price: { bsonType: \"double\", minimum: 0 },\n        category: { enum: [\"electronics\", \"clothing\", \"food\"] }\n      }\n    }\n  }\n})\n\ndb.products.insertOne({ price: \"free\" })\n// Error: \"price\" must be double, got string\n// Data quality enforced at database level!",
      "language": "javascript",
      "description": "JSON Schema catches errors at insert"
    },
    {
      "ruleId": "validation-rollout-strategy",
      "ruleTitle": "Roll Out Schema Validation Safely (Warn to Error)",
      "type": "bad",
      "code": "// Existing collection has legacy documents\n// Enabling strict validation can reject writes unexpectedly\n\ndb.runCommand({\n  collMod: \"users\",\n  validator: { $jsonSchema: { bsonType: \"object\", required: [\"email\"] } },\n  validationAction: \"error\",\n  validationLevel: \"strict\"\n})",
      "language": "javascript",
      "description": "enable strict validation immediately"
    },
    {
      "ruleId": "validation-rollout-strategy",
      "ruleTitle": "Roll Out Schema Validation Safely (Warn to Error)",
      "type": "good",
      "code": "// Phase 1: warn-only while you audit and fix data\n\ndb.runCommand({\n  collMod: \"users\",\n  validator: { $jsonSchema: { bsonType: \"object\", required: [\"email\"] } },\n  validationAction: \"warn\",\n  validationLevel: \"moderate\"\n})\n\n// Phase 2: after backfill, enforce strictly\n\ndb.runCommand({\n  collMod: \"users\",\n  validationAction: \"error\",\n  validationLevel: \"strict\"\n})",
      "language": "javascript",
      "description": "staged rollout"
    }
  ]
}
